{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Textual Augmenter Usage<a class=\"anchor\" id=\"home\"></a>:\n",
    "* [Character Augmenter](#chara_aug)\n",
    "    * [OCR](#ocr_aug)\n",
    "    * [Keyboard](#keyboard_aug)\n",
    "    * [Random](#random_aug)\n",
    "* [Word Augmenter](#word_aug)\n",
    "    * [Spelling](#spelling_aug)\n",
    "    * [Word Embeddings](#word_embs_aug)\n",
    "    * [TF-IDF](#tfidf_aug)\n",
    "    * [Contextual Word Embeddings](#context_word_embs_aug)\n",
    "    * [WordNet](#word_net_aug)\n",
    "    * [Random Word Augmenter](#random_word_aug)\n",
    "* [Sentence Augmenter](#sent_aug)\n",
    "    * [Contextual Word Embeddings for Sentence](#context_word_embs_sentence_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MODEL_DIR\"] = '../model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "\n",
    "from nlpaug.util import Action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox jumps over the lazy dog .\n"
     ]
    }
   ],
   "source": [
    "text = 'The quick brown fox jumps over the lazy dog .'\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Augmenter<a class=\"anchor\" id=\"chara_aug\">\n",
    "\n",
    "Augmenting data in character level. Possible scenarios include image to text and chatbot. During recognizing text from image, we need to optical character recognition (OCR) model to achieve it but OCR introduces some errors such as recognizing \"o\" and \"0\". `OCRAug` simulate these errors to perform the data augmentation. For chatbot, we still have typo even though most of application comes with word correction. Therefore, `QWERTYAug` is introduced to similar this kind of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR Augmenter<a class=\"anchor\" id=\"ocr_aug\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Substitute character by pre-defined OCR error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog\n",
      "Augmented Text:\n",
      "The quick 6rown fux jumps over the lazy dog\n"
     ]
    }
   ],
   "source": [
    "aug = nac.OcrAug()\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keyboard Augmenter<a class=\"anchor\" id=\"keyboard_aug\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Substitute character by keyboard distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog\n",
      "Augmented Text:\n",
      "Tbe quiSk nrown fIx jKmps ov2r tje laAy don\n"
     ]
    }
   ],
   "source": [
    "aug = nac.QwertyAug()\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Augmenter<a class=\"anchor\" id=\"random_aug\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insert character randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog\n",
      "Augmented Text:\n",
      "T3he quicNk @brown fEox juamps $over th6e la1zy d*og\n"
     ]
    }
   ],
   "source": [
    "aug = nac.RandomCharAug(action=\"insert\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Substitute character randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog\n",
      "Augmented Text:\n",
      "ThN qDick brow0 foB jumks oveE t+e laz6 dBg\n"
     ]
    }
   ],
   "source": [
    "aug = nac.RandomCharAug(action=\"substitute\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Swap character randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog\n",
      "Augmented Text:\n",
      "Hte quikc borwn fxo jupms ovre teh lzay dgo\n"
     ]
    }
   ],
   "source": [
    "aug = nac.RandomCharAug(action=\"swap\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Delete character randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog\n",
      "Augmented Text:\n",
      "Te quic rown fx jump ver he laz og\n"
     ]
    }
   ],
   "source": [
    "aug = nac.RandomCharAug(action=\"delete\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Augmenter<a class=\"anchor\" id=\"word_aug\"></a>\n",
    "\n",
    "Besides character augmentation, word level is important as well. We make use of word2vec (Mikolov et al., 2013), GloVe (Pennington et al., 2014), fasttext (Joulin et al., 2016), BERT(Devlin et al., 2018) and wordnet to insert and substitute similar word. `Word2vecAug`,  `GloVeAug` and `FasttextAug` use word embeddings to find most similar group of words to replace original word. On the other hand, `BertAug` use language models to predict possible target word. `WordNetAug` use statistics way to find the similar group of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spelling Augmenter<a class=\"anchor\" id=\"spelling_aug\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Substitute word by spelling mistake words dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog\n",
      "Augmented Text:\n",
      "The quick borwn fox jumps over the lazy gog\n"
     ]
    }
   ],
   "source": [
    "aug = naw.SpellingAug(os.environ[\"MODEL_DIR\"] + 'spelling_en.txt')\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings Augmenter<a class=\"anchor\" id=\"word_embs_aug\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insert word randomly by word embeddings similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog\n",
      "Augmented Text:\n",
      "The quick brown fox jumps Alzeari over the lazy Superintendents dog\n"
     ]
    }
   ],
   "source": [
    "# model_type: word2vec, glove or fasttext\n",
    "aug = naw.WordEmbsAug(\n",
    "    model_type='word2vec', model_path=model_dir+'GoogleNews-vectors-negative300.bin',\n",
    "    action=\"insert\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Substitute word by word2vec similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog\n",
      "Augmented Text:\n",
      "The easy brown fox jumps around the lazy dog\n"
     ]
    }
   ],
   "source": [
    "# model_type: word2vec, glove or fasttext\n",
    "aug = naw.WordEmbsAug(\n",
    "    model_type='word2vec', model_path=model_dir+'GoogleNews-vectors-negative300.bin',\n",
    "    action=\"substitute\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Augmenter<a class=\"anchor\" id=\"tfidf_aug\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insert word by TF-IDF similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog\n",
      "Augmented Text:\n",
      "sinks The quick brown fox jumps over the lazy Sidney dog\n"
     ]
    }
   ],
   "source": [
    "aug = naw.TfIdfAug(\n",
    "    model_path=os.environ.get(\"MODEL_DIR\"),\n",
    "    action=\"insert\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Substitute word by TF-IDF similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog\n",
      "Augmented Text:\n",
      "The quick brown fox Baked over the polygraphy dog\n"
     ]
    }
   ],
   "source": [
    "aug = naw.TfIdfAug(\n",
    "    model_path=os.environ.get(\"MODEL_DIR\"),\n",
    "    action=\"substitute\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextual Word Embeddings Augmenter<a class=\"anchor\" id=\"context_word_embs_aug\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insert word by contextual word embeddings (BERT or XLNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog\n",
      "Augmented Text:\n",
      "even the quick brown fox usually jumps over the lazy dog\n"
     ]
    }
   ],
   "source": [
    "# model_path: bert-base-uncased or xlnet-base-cased\n",
    "aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased', action=\"insert\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Substitute word by contextual word embeddings (BERT or XLNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog\n",
      "Augmented Text:\n",
      "little quick brown fox jumps over the lazy dog\n"
     ]
    }
   ],
   "source": [
    "# model_path: bert-base-uncased or xlnet-base-cased\n",
    "aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased', action=\"insert\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WordNet Augmenter<a class=\"anchor\" id=\"word_net_aug\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Substitute word by synonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog\n",
      "Augmented Text:\n",
      "The straightaway brown fox jumps over the faineant dog\n"
     ]
    }
   ],
   "source": [
    "aug = naw.WordNetAug()\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Word Augmenter<a class=\"anchor\" id=\"random_word_aug\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Swap word randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = nac.RandomWordAug(action=\"swap\")\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Delete word randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog\n",
      "Augmented Text:\n",
      "The brown jumps over the lazy dog\n"
     ]
    }
   ],
   "source": [
    "aug = naw.RandomWordAug()\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextual Word Embeddings for Sentence Augmenter<a class=\"anchor\" id=\"context_word_embs_sentence_aug\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Insert sentnece by contextual word embeddings (GPT2 or XLNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Text:\n",
      "The quick brown fox jumps over the lazy dog . There are odd moments in a version that appears un - - and completely headed for its welcome.\n"
     ]
    }
   ],
   "source": [
    "# model_path: xlnet-base-cased or gpt2\n",
    "aug = nas.ContextualWordEmbsForSentenceAug(model_path='xlnet-base-cased')\n",
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flow Augmentation\n",
    "\n",
    "To make use of multiple augmentation, `sequential` and `sometimes` pipelines are introduced to connect augmenters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply different augmenters sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'&The b0rown jum@ps ovear %the 1lazy gdog'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug = naf.Sequential([\n",
    "    nac.RandomCharAug(action=\"insert\"),\n",
    "    naw.RandomWordAug()\n",
    "])\n",
    "\n",
    "aug.augment(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply some augmenters randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The quick brown fox jumps over the lazy dog'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug = naf.Sometimes([\n",
    "    nac.RandomCharAug(action=\"delete\"),\n",
    "    nac.RandomCharAug(action=\"insert\"),\n",
    "    naw.RandomWordAug()\n",
    "])\n",
    "\n",
    "aug.augment(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
